{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NeHAhwjZdmbJ",
        "outputId": "96b8d5c9-23df-4647-b98b-567b1ab43134"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: numba in /usr/local/lib/python3.10/dist-packages (0.58.1)\n",
            "Requirement already satisfied: llvmlite<0.42,>=0.41.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba) (0.41.1)\n",
            "Requirement already satisfied: numpy<1.27,>=1.22 in /usr/local/lib/python3.10/dist-packages (from numba) (1.25.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (1.25.2)\n"
          ]
        }
      ],
      "source": [
        "# Step 1: Install required libraries\n",
        "!pip install numba\n",
        "!pip install numpy\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Step 2: Import necessary libraries\n",
        "%matplotlib inline\n",
        "from matplotlib import pyplot as plt\n",
        "import numpy as np\n",
        "import math\n",
        "from numba import jit, njit, vectorize, cuda\n"
      ],
      "metadata": {
        "id": "CIbtP-BylGrj"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Step 3: Setting up the environment for GPU\n",
        "# Find the locations of the necessary libraries\n",
        "!find / -iname 'libdevice'\n",
        "!find / -iname 'libnvvm.so'\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a4P_3FvTlKkM",
        "outputId": "4b65e067-7086-48e4-94c4-ecb838304586"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/jaxlib/cuda/nvvm/libdevice\n",
            "/usr/local/cuda-12.2/nvvm/libdevice\n",
            "find: ‘/proc/59/task/59/net’: Invalid argument\n",
            "find: ‘/proc/59/net’: Invalid argument\n",
            "/usr/local/cuda-12.2/nvvm/lib64/libnvvm.so\n",
            "find: ‘/proc/59/task/59/net’: Invalid argument\n",
            "find: ‘/proc/59/net’: Invalid argument\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Set the environment variables (you might need to adjust these paths based on the output of the above commands)\n",
        "import os\n",
        "os.environ['NUMBAPRO_LIBDEVICE'] = \"/usr/local/lib/python3.10/dist-packages/jaxlib/cuda/nvvm/libdevice\"\n",
        "os.environ['NUMBAPRO_NVVM'] = \"/usr/local/cuda-12.2/nvvm/libdevice\"\n",
        "\n"
      ],
      "metadata": {
        "id": "ssbWKzshlOn7"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 4: Vector Addition on GPUs using Numba\n",
        "@vectorize(['int64(int64, int64)'], target='cuda')\n",
        "def add_ufunc_gpu(x, y):\n",
        "    return x + y\n",
        "\n",
        "x = np.arange(10)\n",
        "y = 2 * x\n",
        "print(\"GPU Vector Addition Output: \", add_ufunc_gpu(x, y))\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L-2ht7qPlRBx",
        "outputId": "ab5c4ac9-f014-4e39-f22e-728d638da939"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPU Vector Addition Output:  [ 0  3  6  9 12 15 18 21 24 27]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/numba/cuda/dispatcher.py:536: NumbaPerformanceWarning: Grid size 1 will likely result in GPU under-utilization due to low occupancy.\n",
            "  warn(NumbaPerformanceWarning(msg))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 5: Timing the GPU function\n",
        "%timeit add_ufunc_gpu(x, y)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OSafILPJlT1X",
        "outputId": "412381e1-19c8-4e4d-92ff-18aac9bf0da1"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.53 ms ± 649 µs per loop (mean ± std. dev. of 7 runs, 1000 loops each)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 6: Compare with CPU version\n",
        "@vectorize(['int64(int64, int64)'], target='cpu')\n",
        "def add_ufunc_cpu(x, y):\n",
        "    return x + y\n",
        "\n",
        "%timeit add_ufunc_cpu(x, y)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7dR-KZrAlWIh",
        "outputId": "a8cbe78b-8f57-449d-8935-14e356f04a4f"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.56 µs ± 312 ns per loop (mean ± std. dev. of 7 runs, 1000000 loops each)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 7: Writing CUDA Kernels\n",
        "@cuda.jit\n",
        "def add_kernel(x, y, out):\n",
        "    tidx = cuda.threadIdx.x  # unique thread ID within a 1D block\n",
        "    bidx = cuda.blockIdx.x  # unique block ID within the 1D grid\n",
        "    block_dimx = cuda.blockDim.x  # number of threads per block\n",
        "    grid_dimx = cuda.gridDim.x  # number of blocks in the grid\n",
        "\n",
        "    start = tidx + bidx * block_dimx\n",
        "    stride = block_dimx * grid_dimx\n",
        "\n",
        "    for i in range(start, x.shape[0], stride):\n",
        "        out[i] = x[i] + y[i]\n",
        "\n",
        "n = 100000\n",
        "x = np.arange(n).astype(np.float32)\n",
        "y = 2 * x\n",
        "out = np.empty_like(x)\n",
        "\n",
        "threads_per_block = 128\n",
        "blocks_per_grid = 30\n",
        "\n",
        "add_kernel[blocks_per_grid, threads_per_block](x, y, out)\n",
        "print(out[:10])\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zW4_paBelYVS",
        "outputId": "16ccd535-8dfc-4d57-c716-6e1557a2f65e"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ 0.  3.  6.  9. 12. 15. 18. 21. 24. 27.]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/numba/cuda/dispatcher.py:536: NumbaPerformanceWarning: Grid size 30 will likely result in GPU under-utilization due to low occupancy.\n",
            "  warn(NumbaPerformanceWarning(msg))\n",
            "/usr/local/lib/python3.10/dist-packages/numba/cuda/cudadrv/devicearray.py:886: NumbaPerformanceWarning: Host array used in CUDA kernel will incur copy overhead to/from device.\n",
            "  warn(NumbaPerformanceWarning(msg))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 8: Using Numba helper functions for CUDA Kernels\n",
        "@cuda.jit\n",
        "def add_kernel_simplified(x, y, out):\n",
        "    start = cuda.grid(1)\n",
        "    stride = cuda.gridsize(1)\n",
        "    for i in range(start, x.shape[0], stride):\n",
        "        out[i] = x[i] + y[i]\n",
        "\n"
      ],
      "metadata": {
        "id": "1vtgeQSwlaKd"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 9: Memory Management\n",
        "x_device = cuda.to_device(x)\n",
        "y_device = cuda.to_device(y)\n",
        "out_device = cuda.device_array(shape=(n), dtype=np.float32)\n",
        "\n",
        "%timeit add_kernel_simplified[blocks_per_grid, threads_per_block](x_device, y_device, out_device)\n",
        "%timeit add_kernel_simplified[blocks_per_grid, threads_per_block](x, y, out)\n",
        "\n",
        "out = out_device.copy_to_host()\n",
        "print(\"Output from device array: \", out[:10])\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D2yaOlzWlbnz",
        "outputId": "5db3b313-6af1-4209-89c2-2e0e37f97a49"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/numba/cuda/dispatcher.py:536: NumbaPerformanceWarning: Grid size 30 will likely result in GPU under-utilization due to low occupancy.\n",
            "  warn(NumbaPerformanceWarning(msg))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "57.1 µs ± 9.66 µs per loop (mean ± std. dev. of 7 runs, 10000 loops each)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/numba/cuda/cudadrv/devicearray.py:886: NumbaPerformanceWarning: Host array used in CUDA kernel will incur copy overhead to/from device.\n",
            "  warn(NumbaPerformanceWarning(msg))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.39 ms ± 371 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n",
            "Output from device array:  [ 0.  3.  6.  9. 12. 15. 18. 21. 24. 27.]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 10: Scaling up the problem size\n",
        "n = 100000\n",
        "x = np.arange(n).astype(np.float32)\n",
        "y = 2 * x\n",
        "x_device = cuda.to_device(x)\n",
        "y_device = cuda.to_device(y)\n",
        "out_device = cuda.device_array(shape=(n), dtype=np.float32)\n",
        "\n",
        "%timeit add_kernel_simplified[blocks_per_grid, threads_per_block](x_device, y_device, out_device)\n",
        "%timeit add_kernel_simplified[blocks_per_grid, threads_per_block](x, y, out)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mxKT9WLUldMD",
        "outputId": "b2d95379-2462-4361-aaf8-75ce56b653ac"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "53.6 µs ± 1.05 µs per loop (mean ± std. dev. of 7 runs, 10000 loops each)\n",
            "1.99 ms ± 142 µs per loop (mean ± std. dev. of 7 runs, 1000 loops each)\n"
          ]
        }
      ]
    }
  ]
}